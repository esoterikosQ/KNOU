---
title: "Untitled"
output: word_document
date: "2023-03-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(reticulate)
library(glmnet)
reticulate::use_condaenv('py4r')
```

## 1. R과 파이썬의 사용에 관한 다음 물음에 답하시오.

(1) 원의 반지름을 받아 면적을 구하는 R 함수문을 작성하고 결과를 보이시오.

```{r 1-1}
round_area <- function(x){
  result <- pi*x^2
  return(result)
}

round_area(5)
```

(2) POWER(X, n)($X^n$)을 구하는 파이썬 함수를 작성하고 결과를 보이시오.

```{python 1-2}
def power(X, n):
  result = X**n
  return result

power(2, 3)
```

(3) 주당 근무시간이 40시간 이내면 시간당 임금이 1만원이고 40시간이 초과되는 부분에대해서는 1.5배를 지급하는 함수를 만들고자 한다.

- 주당 근무시간을 입력받으면 임금이 계산되는 함수를 R로 작성하고 결과의 예를 보이시오.

```{r 1-3-1}
wage_cal <- function(x){
  if(x <= 40) return(x)
  else{
    ot <- x-40
    result <- x + ot*1.5
    return(result)
  }
}

wage_cal(50)
wage_cal(30)
```

- 주당 근무시간을 입력받으면 임금이 계산되는 함수를 파이썬으로 작성하고 결과의 예를 보이시오.

```{python 1-3-2}
def wage_cal(x):
  if x <= 40:
    return x
  else:
    ot = x - 40
    result = x + ot*1.5
    return result

wage_cal(50)
wage_cal(30)
```

(4) a = c(1,4,6,8,9,12,14,19,20)의 값을 받아서 기술통계량을 구하는 R함수를 작성하고자 한다. (평균, 중앙값, 표준편차, 합, 개수)를 결과값으로 반환하는 R함수를 작성하고 결과를 보이시오.

```{r 1-4}
eda <- function(x){
  a <- mean(x)
  b <- median(x)
  c <- sd(x)
  d <- sum(x)
  e <- length(x)
  result <- list('mean' = a, 'median' = b, 'sd' = c, 'sum' = d, 'count' = e)
  return(result)
}

a <- c(1, 4, 6, 8, 9, 12, 14, 19, 20)
eda(a)
```

(5) b = [2,5,8,12,15,16,18,20] 의 값을 받아서 기술통계량을 구하는 파이썬 클래스를 작성하고자 한다. (평균, 중앙값, 표준편차, 합, 개수) 각각을 결과값으로 반환하는 파이썬 함수를 가지는 파이썬 클래스를 작성하고 결과를 보이시오.

```{python 1-5}
class EDA:
  def __init__(self, list): # 생성자
    self.dt = list

  def agg(self): # 합산 함수
    agg = sum(value for value in self.dt)
    return agg
  
  def cnt(self): # 개수 함수
    cnt = len(self.dt)
    return cnt
  
  def avg(self): # 평균 함수
    avg = self.agg()/self.cnt()
    return avg

  def med(self): # 중간값 함수
    self.dt.sort()
    med = 0
    idx = 0
    if len(self.dt)%2 == 0:
      idx = self.cnt()//2
      med = (self.dt[idx-1] + self.dt[idx])/2
    else:
      idx = self.cnt()//2 + 1
      med = self.dt[idx]
    return med

  def std(self): # 표준편차 함수
    avg = self.avg()
    std = (sum((val-avg)**2 for val in self.dt)/self.cnt())**(1/2)
    return std
      
# 클래스 선언
b = [2, 5, 8, 12, 15, 16, 18, 20]
a = EDA(b)
a.avg() # 평균
a.med() # 중앙값
a.std() # 표준편차
a.agg() # 합
a.cnt() # 개수
```


## 2. 두 가지 교육방법을 비교하기 위하여 능력이 유사하다고 생각되는 한 고등학교 학생 22명을 추출하여 11명식 두 집단으로 나누어 한 학기동안 각 교육방법으로 교육시킨 후에 치른 학기말 시험성적이 다음과 같이 얻어졌다. 이 자료를 이용하여 두 가지 교육방법에 대한 국어와 영어의 효과가 서로 다르다고 할 수 있는가를 검정하고자 한다.

```{r 2}
a <- c(65, 87, 73, 79, 81, 69, 55, 76, 77, 70, 88)
b <- c(82, 79, 85, 60, 65, 70, 79, 80, 76, 90, 68)
c <- c(75, 69, 83, 81, 72, 79, 85, 89, 90, 77, 95)
d <- c(72, 75, 93, 85, 60, 65, 88, 92, 83, 93, 78)

method1 <- data.frame('kor' = a, 'eng' = b, 'method' = 1)
method2 <- data.frame('kor' = c, 'eng' = d, 'method' = 2)

dt <- rbind(method1, method2)
write.csv(dt, file = 'ML_1.csv', row.names = F)
```

(1) R을 이용하여 실행하고 결과를 분석하시오.

22명을 두 집단으로 나누어 다른 교육방법으로 교육한 후 두 집단 간 시험성적 비교 독립표본 t검정

```{r 2-1}
# 국어
var.test(kor ~ method, dt) # 등분산
t.test(kor ~ method, dt, var.equal = T) # student's t-test

# 영어
var.test(eng ~ method, dt) # 등분산
t.test(eng ~ method, dt, var.equal = T) # student's t-test
```

(2) 파이썬을 이용하여 실행하고 결과를 분석하시오.

```{python 2-2}
import scipy.stats as stats
import pandas as pd

dt = pd.read_csv('ML_1.csv')

# 국어
stats.f_oneway(dt['kor'][dt['method']==1], dt['kor'][dt['method']==2]) # 등분산검정
stats.ttest_ind(dt['kor'][dt['method']==1], dt['kor'][dt['method']==2], equal_var = True)

# 영어
stats.f_oneway(dt['eng'][dt['method']==1], dt['eng'][dt['method']==2]) # 등분산검정
stats.ttest_ind(dt['eng'][dt['method']==1], dt['eng'][dt['method']==2], equal_var = True)
```

## 3. 다음 자료는 Hald(1960)에 의해 조사된 것으로 1그램의 시멘트에서 발생하는 열(calories)을 반응변수로 하고 시멘트의 4가지 원료의 양을 설명변수로 한다.

```{r 3}
x1 <- c(7, 1, 11, 11, 7, 11, 3, 1, 2, 21, 1, 11, 10)
x2 <- c(26, 29, 56, 31, 52, 55, 71, 31, 54, 47, 40, 66, 68)
x3 <- c(6, 15, 8, 8, 6, 9, 17, 22, 18, 4, 23, 9, 8)
x4 <- c(60, 52, 20, 47, 33, 22, 6, 44, 22, 26, 34, 12, 12)
y <- c(78.5, 74.3, 104.3, 87.6, 95.9, 109.2, 102.7, 72.5, 93.1, 115.9, 83.8, 113.3, 109.4)

dt <- data.frame(x1, x2, x3, x4, y)
write.csv(dt, file = 'ML_2.csv', row.names = F)
```

(1) R을 이용하여 회귀모형을 적합하고, 결과를 해석하시오.

```{r 3-1}
reg_cement <- lm(y~., dt)
summary(reg_cement)
```

(2) 파이썬을 이용하여 회귀모형을 적합하고 R의 결과와 비교하시오.

```{python 3-2}
import pandas as pd
import numpy as np
import statsmodels.formula.api as sm

dt = pd.read_csv('ML_2.csv')

reg_cement = sm.ols(formula = 'y ~ x1 + x2 + x3 + x4', data = dt).fit()
print(reg_cement.summary())


reg_cement = sm.ols('y ~ x1 + x2 + x3 + x4', data = dt).fit()
print(reg_cement.summary())
```

4. R패키지 ISLR에 있는 데이터셋 Hitters는 1986~1987년도 미국 메이저리그 타자 자료이다. 자료는 다음과 같다. 이 자료에서 salary를 종속변수로 한 모형을 적합하고자 한다.

```{r 4}
# data loading
library(ISLR)
dt <- Hitters
```

(1) R 시스템에서 먼저 결측치 자료를 없앤 후, ridge regression 및 lasso regression을 적합하고 결과를 해석하시오.
https://rpago.tistory.com/59
https://analysisbugs.tistory.com/199

```{r 4-1-1 preprocessing}
# 결측치 제거
dim(dt) # 322*20 데이터
dt <- dt[complete.cases(dt),]
dim(dt) # 263*20 데이터로 정리

## divide explain & response variables
X <- model.matrix(Salary~., dt)[,-1] #dt[names(dt) != 'Salary'])
y <- dt$Salary

## divide train & test dataset
train_idx <- sample(1:nrow(X), nrow(X)/2)

# 파이썬 분석을 위해 csv 파일로 export
write.csv(dt, file = 'ML_3.csv', row.names = F)
```

릿지회귀분석 - 데이터셋을 train, test으로 나눠서 train으로 k-fold 교차검증해서 최적의 lambda값을 찾아내고 그 값을 test에 적합해서 추정 MSE를 구하고 동일한 조건에서 구한 다중선형회귀 모형의 추정 MSE값과 비교

```{r 4-1-2 linear model}
# multiple linear regression
model_lm <- lm(y~X, subset = train_idx) #y[train_idx] ~ X[train_idx,])
model_lm_hat <- predict(model_lm, newx = X[-train_idx,])
mean((model_lm_hat - y[-train_idx])**2) # estimate MSE = 310760.4
coef_lm <- model_lm$coefficients
coef_lm
```

```{r 4-1-3 ridge}
# ridge regression
## fitting
model_ridge <- glmnet(X[train_idx,], y[train_idx], alpha = 0) # alpha는 elasticnet param으로, 0이면 릿지, 1이면 라쏘

## plotting
plot(model_ridge, xvar = 'lambda', label = T,
     main = 'Ridge regression coefficient shrinkage vs log lambda')

## k-fold cross validation
ridge_cv <- cv.glmnet(X[train_idx, ], y[train_idx], alpha = 0)
plot(ridge_cv, main = 'Ridge regression cross validation error(10 fold)')
best_lambda <- ridge_cv$lambda.min

## estimated MSE
best_ridge_hat <- predict(model_ridge, s = best_lambda, newx = X[-train_idx, ])
mean((best_ridge_hat - y[-train_idx])**2) # estimated MSE = 115115.2

## final model
model_ridge_final <- glmnet(X, y, alpha = 0)
coef_ridge <- predict(model_ridge_final, s = best_lambda, type = 'coefficients')
```


```{r 4-1-4 lasso}
model_lasso <- glmnet(X[train_idx,], y[train_idx], alpha = 1) # alpha는 elasticnet param으로, 0이면 릿지, 1이면 라쏘

## plotting
plot(model_lasso, xvar = 'lambda', label = T,
     main = 'Lasso regularization - coefficient shrinkage vs log lambda')

## k-fold cross validation
lasso_cv <- cv.glmnet(X[train_idx, ], y[train_idx], alpha = 1)
plot(lasso_cv, main = 'Lasso regularization cross validation error(10 fold)')
best_lambda <- lasso_cv$lambda.min

## estimated MSE
best_lasso_hat <- predict(model_lasso, s = best_lambda, newx = X[-train_idx, ])
mean((best_lasso_hat - y[-train_idx])**2) # estimated MSE = 118056.6

## final model
model_lasso_final <- glmnet(X, y, alpha = 1)
coef_lasso <- predict(model_lasso_final, s = best_lambda, type = 'coefficients')
```

```{r 4-1-6 comparison}
coef_comp <- data.frame(as.matrix(coef_lm), as.matrix(coef_ridge), as.matrix(coef_lasso))
names(coef_comp) = c('lm', 'ridge', 'lasso')
coef_comp
```

(2) 야구 자료 데이터셋을 파일로 저장한 후, 파이썬을 이용하여 ridge regression 및 lasso regression을 적합하고 R의 결과와 비교하시오.

```{python 4-2-1 preprocessing}
# import necessary packages
import os
from sklearn.preprocessing import MinMaxScaler
import sklearn.linear_model as lm
from sklearn.model_selection import train_test_split

# import dataset
dt = pd.read_csv('ML_3.csv')

# divide explain and response variables
X = dt.iloc[:, dt.columns != 'Salary']
y = dt.iloc[:, dt.columns == 'Salary']

## league
X['League'] = X.League.astype('category').cat.codes
## division
X['Division'] = X.Division.astype('category').cat.codes
## newleague
X['NewLeague'] = X.NewLeague.astype('category').cat.codes

# train, test 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)

# scale
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.fit_transform(X_test)
```

```{python 4-2-2 ridge}
# ridge
## fitting
## alpha = 1이 기본 설정, R의 glmnet함수와는 달리 alpha값은 L2 가중치(glmnet에서의 lambda)
model_ridge = lm.Ridge().fit(X_train_scaled, y_train)

## R^2 of the training model
print('R-squared score (training): {:.3f}'.format(model_ridge.score(X_train_scaled, y_train))) # R^2 = 0.484
print('R-squared score (test): {:.3f}'.format(model_ridge.score(X_test_scaled, y_test))) # hat{R^2} = 0.448

## alpha - weight plot (glmnet에서의 lambda-coef plot)
import matplotlib.pyplot as plt
coefs = []
alphas = 10**np.linspace(10, -2, 100)*0.5

# Train the model with different regularisation strengths
for a in alphas:
    ridge = lm.Ridge(alpha = a)
    ridge.fit(X_train_scaled, y_train)
    coefs.append(ridge.coef_[0])

# Display results
ax = plt.gca()
ax.plot(alphas, coefs)
ax.set_xscale("log")
plt.xlabel("alpha")
plt.ylabel("weights")
plt.title("Ridge coefficients as a function of the regularization")
plt.axis("tight")

plt.show()
```

```{python 4-2-3 ridgeCV}
from sklearn.metrics import mean_squared_error
# calculate mse of regular linear regression
linear_reg = lm.Ridge(alpha = 0)
linear_reg.fit(X_train_scaled, y_train)
mean_squared_error(y_test, linear_reg.predict(X_test_scaled)) # mse = 164103


# calculate the best alpha
ridgecv = lm.RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error')
ridgecv.fit(X_train_scaled, y_train)
ridgecv.alpha_

# calculate MSE under the best alpha
best_ridge = lm.Ridge(alpha = ridgecv.alpha_)
best_ridge.fit(X_train_scaled, y_train)
mean_squared_error(y_test, best_ridge.predict(X_test_scaled)) # mse = 159646
```
```{python 4-2-4 lasso}
# fitting
linlasso = lm.Lasso(alpha = 0.1, max_iter = 10000).fit(X_train_scaled, y_train)

# R^2 and coefs
print('Non-zero features: {}'
     .format(np.sum(linlasso.coef_ != 0))) # n of non-zero coefs = 17
print('R-squared score (training): {:.3f}'
     .format(linlasso.score(X_train_scaled, y_train)))  # R^2 = 0.495
print('R-squared score (test): {:.3f}\n'
     .format(linlasso.score(X_test_scaled, y_test))) # hat{R^2} = 0.458
print('Features with non-zero weight (sorted by absolute magnitude):')

for e in sorted (list(zip(list(X), linlasso.coef_)),
                key = lambda e: -abs(e[1])):
    if e[1] != 0:
        print('\t{}, {:.3f}'.format(e[0], e[1]))
        
# alpha-weight plot
coefs = []

# Train the model with different regularisation strengths
for a in alphas:
    lasso = lm.Lasso(alpha = a, max_iter = 10000)
    lasso.fit(X_train_scaled, y_train)
    coefs.append(lasso.coef_[0])

# Display results
ax = plt.gca()
ax.plot(alphas, coefs)
ax.set_xscale("log")
plt.xlabel("alpha")
plt.ylabel("weights")
plt.title("Lasso coefficients as a function of the regularization")
plt.axis("tight")

plt.show()
```

```{python 4-2-5 lassoCV}
# calculate the best alpha
lassocv = lm.LassoCV(alphas = alphas, max_iter = 10000)
lassocv.fit(X_train_scaled, y_train)

# calculate MSE under the best alpha
best_lasso = lm.Lasso(alpha = lassocv.alpha_)
best_lasso.fit(X_train_scaled, y_train)
mean_squared_error(y_test, best_lasso.predict(X_test_scaled)) # mse = 157990
```


```{python 4-2-5 coefs}
df_coef = pd.concat([pd.Series(linear_reg.coef_[0]), pd.Series(best_ridge.coef_[0]), pd.Series(best_lasso.coef_)], 
                    axis = 1)
df_coef.columns = ['Regular', 'Ridge', 'Lasso']
df_coef.index = X.columns
df_coef
```

참고자료
https://rpago.tistory.com/59
http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-py.html


5. R 'ade4'패키지에 있는 'deug' 자료를 이용하여 주성분분석을 실시하고자 한다. 다음에 답하시오.

```{r 5}
library(ade4)
data(deug)

var(deug$tab)
# 각 과목의 분산 차이가 심함, 점수 단위는 같지만 표준화를 통해 과목 간 편차를 조정
```

(1) R을 이용하여 주성분분석을 실시하시오.

```{r 5-1 PCA}
library(dplyr)
library(ggplot2)

deugPCA = prcomp(deug$tab, scale = T)
summary(deugPCA)
screeplot(deugPCA, type = 'l', pch = 1, main = 'Scree Plot')
# 2번 성분까지 포함

deugPCA$rotation[, 1:2]
# 1성분 - 수리적 사고
# 2성분 - 문리적 사고

dt <- data.frame(deugPCA$x)
dt1 <- cbind(dt, deug$result)

# plot for pc1 and pc2
ggplot(dt1, aes(x = PC1, y = PC2, col = deug$result)) +
  geom_point() + ggtitle("Top 2 Principlal Components")
```


(2) 데이터를 csv파일로 저장한 후, 파이썬을 이용하여 주성분분석을 실시하고, R의 결과와 비교하시오.

```{r 5-2-1}
dt = cbind(deug$tab, deug$result)
colnames(dt)[10] <- 'result'
write.csv(dt, file = 'deug.csv', row.names = F)
```

```{python 5-2-2}
from sklearn import decomposition as dec
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# preprocessing + normalization
dt = pd.read_csv('deug.csv')
dt['result_idx'] = dt['result'].replace({'A+': 5, 'A':4, 'B':3, 'B-':2, 'C-':1, 'D':0})
dt.iloc[:, 0:8] = StandardScaler().fit_transform(dt.iloc[:, 0:8])

# pca fitting
pca = dec.PCA(4)
projected = pca.fit_transform(dt.iloc[:,0:8])

# result stats
pca.explained_variance_ratio_
np.round(pca.components_, 3)

# scree plot
plt.title('Scree Plot')
plt.xlabel('Components')
plt.ylabel('Explained Variance')
plt.plot(pca.explained_variance_, 'o-')
plt.show()


# scatter plot
plt.scatter(x = projected[:, 0], y = projected[:, 1],
           c = dt['result_idx'], edgecolor = 'none', alpha = 0.5,
           cmap = 'Spectral_r') #
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.colorbar()
plt.title('Top 2 Principal Components')
plt.show()
```

## 6. 다음은 1973년 미국 각 주의 강력범죄 자료이다. 변수 murder, asault, rape는 인구 100,000명당 사고 건수이고, urbanpop는 도시인구 비율이다. 이 자료를 이용하여 주성분분석을 하고자 한다.

(1) R을 이용하여 실행하고 결과를 해석하시오.

```{r 6-1}
dt <- read.csv(file = '(ml)crime.csv')
var(dt[,2:5])

dtPCA <- prcomp(dt[,2:5], scale = T)
summary(dtPCA)
screeplot(dtPCA, type = 'l', pch = 1, main = 'Scree Plot')
# pc1, pc2 선택

dtPCA$rotation[,1:2]
# pc1 : 범죄요인, pc2 : 인구요인

dt1 <- cbind(data.frame(dtPCA$x), dt$state)
colnames(dt1)[5] <- 'state'

# 시각화
ggplot(dt1, aes(x = PC1, y = PC2)) +
  geom_point() + geom_text(aes(label = state), size = 3, vjust = 2) +
  ggtitle("Top 2 Principlal Components")
```

(2) 파이썬을 이용하여 실행하고 R의 결과와 비교하시오.

```{python 6-2}
from sklearn import decomposition as dec
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

dt = pd.read_csv('(ml)crime.csv')
dt.iloc[:, 1:4] = StandardScaler().fit_transform(dt.iloc[:, 1:4])

# fitting
pca = dec.PCA(2)
projected = pca.fit_transform(dt.iloc[:,1:4])

# result stats
pca.explained_variance_ratio_
np.round(pca.components_, 3)

# scree plot
plt.title('Scree Plot')
plt.xlabel('Components')
plt.ylabel('Explained Variance')
plt.plot(pca.explained_variance_, 'o-')
plt.show()

# scatter plot
plt.scatter(x = projected[:, 0], y = projected[:, 1])

for i in range(len(dt)):
    row = dt.iloc[i]
    name = row['state']
    x = projected[i, 0]
    y = projected[i, 1]
    plt.text(x+0.05, y-0.05, name, fontsize = 10)

plt.title('Top 2 Principal Components')
plt.show()
```



## 7. R 패지 'HSAUR'에 있는 'watervoles' 데이터를 가져와 MDS 분석을 하고자 한다.

```{r 7}
library(HSAUR)
data(watervoles)

write.csv(watervoles, file = 'ML_3.csv')
```

(1) R을 이용하여 MDS를 시행한 결과를 보이고, 분석하시오.

```{r 7-1}
library(smacof)
mdsWV <- smacofSym(watervoles, ndim  = 2)
mdsWV

plot(mdsWV$conf[,1], mdsWV$conf[,2], type = 'n', xlab = '', ylab = '', main = 'MDS of Water Voles Data')
text(mdsWV$conf[,1], mdsWV$conf[,2], rownames(watervoles), cex = 0.9)
abline(h = 0, v = 0, lty = 3)
```

```{r 7-1-2 screeplot}
scplt <- function(){
  strval = vector()
  for (i in seq(1, 4, 1)){
    mds_res <- smacofSym(watervoles, ndim = i)
    strval <- c(strval, mds_res$stress)
  }
  plot(strval, type = 'l', 
       xlab = 'no of dimesion', ylab = 'stress value', main = 'Scree Plot by no of Dimension')
  points(strval, cex = 0.9)
}

scplt()
```

(2) csv파일로 저장한 후, 파이썬을 이용하여 MDS를 시행하고 R의 결과와 비교하여 설명하시오.

```{python 7-2 mds}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import MDS

dt = pd.read_csv('ML_3.csv', index_col = 0)

mdsWV = MDS(dissimilarity = 'precomputed', n_components = 2, random_state = 40, max_iter = 1000, eps = 1e-9)
X = mdsWV.fit_transform(dt)

theta = 80*np.pi / 180
rot = np.array([[np.cos(theta), np.sin(theta)],
               [np.sin(theta), -np.cos(theta)]])
Xr = np.dot(X, rot)

plt.scatter(Xr[:, 0], Xr[:, 1])

for i in range(len(dt)):
    plt.text(Xr[i, 0], Xr[i, 1]-0.03, dt.index[i])
plt.axis('equal')
plt.xlabel('Dim1')
plt.ylabel('Dim2')
plt.title('MDS of Water Voles Data')
plt.show()
```

```{python 7-2-2 screeplot}
k_range = range(1, 5)
stress = [MDS(dissimilarity = 'precomputed', n_components = k, random_state = 42,
             max_iter = 300, eps = 1e-9).fit(dt).stress_ for k in k_range]

plt.plot(k_range, stress)
plt.xlabel('no of dim')
plt.ylabel('stress value')
plt.title('Scree Plot by no of dimension')
plt.show()
```




(참조자료)
https://rpago.tistory.com/59
